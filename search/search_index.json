{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Meshroom A command-line tool to build and manage Cybersecurity Mesh Architectures (CSMA). Philosophy As defined by Gartner, a Cybersecurity Mesh Architecture is a graph of interoperated cybersecurity services, each fulfilling a specific functional need (SIEM, EDR, EASM, XDR, TIP, etc ). Adopting the CSMA and Meshroom's philosophy means choosing an interconnected ecosystem of high-quality products with specialized scopes rather than a captive all-in-one solution. It then means : Adopting standard formats and protocols rather than proprietary ones to share data and information between products (STIX, ECS, OCSF, OpenC2, syslog, CEF, etc ) Leveraging Open APIs to make your products communicate and control eachother Exploiting products' extensibility via plugins and open-source components to encourage user-defined interoperability Who ? As a vendor : fight the N-to-N integration curse Cybersecurity vendors know it well : integrating with other cybersecurity products burns time and human resources . Integration teams feel so sad when every vendor has to spend those resources developing an integration with every other vendor, without work factorization : this is the N-to-N integration curse . This curse mostly originates from: Poor adoption of standard formats, protocols and API layouts to interoperate cybersecurity solutions Lack of open resources and documentation to start communicating and controling a given product Small actors are overwhelmed by the numerous integration opportunities with major actors, but won't factorise their contributions to make one integration suit all 3rd-party products Every actor must keep hundreds of vendor-specific integrations up to date according to hundreds of non-coordinated roadmaps and constantly breaking changes Meshroom helps cybersecurity vendors build integrations between their products and other solutions, keeping the integration burden as low a possible. To do so, meshroom comes with a set of predefined product templates categorized according to Gartner's Hype Cycle for Security Operations, 2024 that help you scaffolding full product definitions. By publishing your product's functional surface from one of this template, you encourage the adoption of open API layouts, formats and protocols. Whereby, you contributes to turn the N-to-N integration burden into an ideal repository of N reusable product definitions , where every new vendor can effortlessly plug with the N previously declared products. As a MSSP : setup a full cybersecurity mesh via declarative and versionable manifests Setting up a SOC is also a time-consuming operation. Sadly, MSSPs in charge of many similar information systems will often repeat those very same time-consuming steps again and again, switching from one solution's configuration interface to another one's admin console. Eventually, this will involve wildly manipulating API keys and admin forms, resulting in errors, security holes and blind spots. Many MSSPs maintain a run book of manual setup steps, and most of them automate part of those steps to get a SOC up-and-running within, say, days or perhaps hours... Meshroom helps DevSec operators to setup a full meshed SOC made of dozens of tenants in a single CLI command : meshroom up . Because Meshroom projects are versioned , you can push and share SOC architectures via GitHub or your favorite forge, while keeping trace of every setup and provisioning processes executed. You can think of meshroom up as the cyber mesh equivalent of Infrastructure-as-code's terraform apply or containerized stack's docker compose up . When your SOC grows to dozens of interoperated products, it becomes hard to visualize where data and controls flow between them. Meshroom provides an easy to use graph model documenting: all capabilities exposed by the products you are using all available integrations they offer to other products all the active connections (know as Plugs within Meshroom) between products (aka producer / consumer and trigger / executor relationships) As a developer : painless DX to build and publish custom product additions Many cybersecurity platforms offer extensibility capabilities via plugins , custom formats, custom rules, custom actions, etc . Here again, there's no accepted standard and every vendor defines its own approach (YAML files, python code, no-code workflows, etc ). Yet, products interoperability often rely on contributing custom additions to one or both ends. Of course, this scope is often badly documented, and developers are left with trial-and-error quasi-reverse ninja approaches to understand how to make product A talk to product B. In the end, you'll eventually succeed in getting a working plugin, but then face the un-coordinated maze of homologation processes each vendor mandates to make your contribution public . Meshroom helps cybersecurity vendors to expose a single standard contribution model for: setting up custom software additions when interoperability mandates so compiling everything into a product plugin suitable for publication publishing as a PR to GitHub or other marketplaces Meshroom also eases the tedious \"playground\" phase where developers need to send test data to their trial 3rd-party instances, trigger remote commands from their workstation, watch results, make changes to their integration in an agile continous development workflow: meshroom produce helps you sending data through plugged integrations meshroom watch helps you watching data flowing through a plugged integration","title":"Meshroom"},{"location":"#meshroom","text":"A command-line tool to build and manage Cybersecurity Mesh Architectures (CSMA).","title":"Meshroom"},{"location":"#philosophy","text":"As defined by Gartner, a Cybersecurity Mesh Architecture is a graph of interoperated cybersecurity services, each fulfilling a specific functional need (SIEM, EDR, EASM, XDR, TIP, etc ). Adopting the CSMA and Meshroom's philosophy means choosing an interconnected ecosystem of high-quality products with specialized scopes rather than a captive all-in-one solution. It then means : Adopting standard formats and protocols rather than proprietary ones to share data and information between products (STIX, ECS, OCSF, OpenC2, syslog, CEF, etc ) Leveraging Open APIs to make your products communicate and control eachother Exploiting products' extensibility via plugins and open-source components to encourage user-defined interoperability","title":"Philosophy"},{"location":"#who","text":"","title":"Who ?"},{"location":"#as-a-vendor-fight-the-n-to-n-integration-curse","text":"Cybersecurity vendors know it well : integrating with other cybersecurity products burns time and human resources . Integration teams feel so sad when every vendor has to spend those resources developing an integration with every other vendor, without work factorization : this is the N-to-N integration curse . This curse mostly originates from: Poor adoption of standard formats, protocols and API layouts to interoperate cybersecurity solutions Lack of open resources and documentation to start communicating and controling a given product Small actors are overwhelmed by the numerous integration opportunities with major actors, but won't factorise their contributions to make one integration suit all 3rd-party products Every actor must keep hundreds of vendor-specific integrations up to date according to hundreds of non-coordinated roadmaps and constantly breaking changes Meshroom helps cybersecurity vendors build integrations between their products and other solutions, keeping the integration burden as low a possible. To do so, meshroom comes with a set of predefined product templates categorized according to Gartner's Hype Cycle for Security Operations, 2024 that help you scaffolding full product definitions. By publishing your product's functional surface from one of this template, you encourage the adoption of open API layouts, formats and protocols. Whereby, you contributes to turn the N-to-N integration burden into an ideal repository of N reusable product definitions , where every new vendor can effortlessly plug with the N previously declared products.","title":"As a vendor : fight the N-to-N integration curse"},{"location":"#as-a-mssp-setup-a-full-cybersecurity-mesh-via-declarative-and-versionable-manifests","text":"Setting up a SOC is also a time-consuming operation. Sadly, MSSPs in charge of many similar information systems will often repeat those very same time-consuming steps again and again, switching from one solution's configuration interface to another one's admin console. Eventually, this will involve wildly manipulating API keys and admin forms, resulting in errors, security holes and blind spots. Many MSSPs maintain a run book of manual setup steps, and most of them automate part of those steps to get a SOC up-and-running within, say, days or perhaps hours... Meshroom helps DevSec operators to setup a full meshed SOC made of dozens of tenants in a single CLI command : meshroom up . Because Meshroom projects are versioned , you can push and share SOC architectures via GitHub or your favorite forge, while keeping trace of every setup and provisioning processes executed. You can think of meshroom up as the cyber mesh equivalent of Infrastructure-as-code's terraform apply or containerized stack's docker compose up . When your SOC grows to dozens of interoperated products, it becomes hard to visualize where data and controls flow between them. Meshroom provides an easy to use graph model documenting: all capabilities exposed by the products you are using all available integrations they offer to other products all the active connections (know as Plugs within Meshroom) between products (aka producer / consumer and trigger / executor relationships)","title":"As a MSSP : setup a full cybersecurity mesh via declarative and versionable manifests"},{"location":"#as-a-developer-painless-dx-to-build-and-publish-custom-product-additions","text":"Many cybersecurity platforms offer extensibility capabilities via plugins , custom formats, custom rules, custom actions, etc . Here again, there's no accepted standard and every vendor defines its own approach (YAML files, python code, no-code workflows, etc ). Yet, products interoperability often rely on contributing custom additions to one or both ends. Of course, this scope is often badly documented, and developers are left with trial-and-error quasi-reverse ninja approaches to understand how to make product A talk to product B. In the end, you'll eventually succeed in getting a working plugin, but then face the un-coordinated maze of homologation processes each vendor mandates to make your contribution public . Meshroom helps cybersecurity vendors to expose a single standard contribution model for: setting up custom software additions when interoperability mandates so compiling everything into a product plugin suitable for publication publishing as a PR to GitHub or other marketplaces Meshroom also eases the tedious \"playground\" phase where developers need to send test data to their trial 3rd-party instances, trigger remote commands from their workstation, watch results, make changes to their integration in an agile continous development workflow: meshroom produce helps you sending data through plugged integrations meshroom watch helps you watching data flowing through a plugged integration","title":"As a developer : painless DX to build and publish custom product additions"},{"location":"concepts/","text":"Concepts Integration lifecycle TODO CYCLE SCHEMA Capabilities graph Formally, a cybersecurity mesh architecture (CSMA) is a directed graph of products talking to eachother. More precisely, it is an overlay of 2 graphs: The capabilities graph , which expresses the set of all products that can be interoperated with eachother and what functional capacity they expose. Nodes of this graph are Product capabilities, and edges connect complementary capabilities. For example, one product may consume alerts produced by another product, or can execute actions triggered by another one. Edges thus characterise interop opportunities about a certain Topic between a source product and a destination product. The direction of the edges materializes the dataflow : the source product produces/triggers information (resp. actions) that the destination product consumes/executes . An edge exists as soon as the products define a compatible producer (or trigger) / consumer (resp. executor) pair of Integrations . The edge also carries the roles in the data exchange in push mode, the producer is active and the consumer is passive ( e.g. a Syslog forwarder) in pull mode, the producer is passive and the consumer is active ( e.g. an HTTP GET API) Therefore, an edge exist between product couples that expose complementary integrations for compatible topics, and match formats or other compatibility criteria you may need to refine the scope of a capability. The density if the capabilities graph measures the \"openness\" of the products constellation ; one wants to maximize the number of allowed interops between cybersecurity solutions available on the market The Mesh graph itself, which is an instanciation of several product Instances connected to eachother by Plugs who leverage compatible Integrations over the underlying capabilities graph. Instances correspond to actual user tenants of the underlying products, and plugs are live connections between those tenants. In order to setup the defined plugs, instances must be configured to enable the corresponding production/consumption triggering/execution logic, potentially via custom additions to the products themselves. Meshroom's spirit is to make all this configuration and provisioning as simple as a single meshroom up command. To do so, Products, Integrations, Instances and Plugs are defined via YAML manifests and vendor code additions when required. All these files belong to a git-backed repository that can be shared, versioned via git and manipulated via the Meshroom CLI, exactly as, say, Helm charts can be shared among a community of Kubernetes users. Some sensitive data , like API keys and other secrets used to teleoperate the Instances are natively held and managed by Meshroom in a local GPG secrets store , that can also be shared following a classical GPG assymetric cryptography process. This decreases the risk of leak resulting from a spread of secrets used to co-ordinate numerous tenants, while easing the sharing of a full read-to-use SOC configuration. Project A Meshroom Project is a git-backed local directory on your computer, following a file structure the Meshroom CLI can understand and manipulate (see Meshroom project structure ). You can start a new meshroom project via meshroom init <path> . This will setup a new local git repo and few minimal files in this directory so that you can start building your integrations and mesh architecture. You can then directly add a git remote via git remote add <remote> <remote_url> such as a GitHub repo to save, share and publish your project via git push , and use the directory as a classical Git repository. Subsequent meshroom commands must be executed at the <path> 's root and will manipulate its files hierarchy. Product In Meshroom, a Product is the definition of a cybersecurity product's capabilities. A Product is primarily defined via a YAML file with: * a name * a textual description of its functional surface and its role in the security ecosystem * a set of tags , expliciting the product category it belongs to ( e.g. , EDR, EASM, SIEM, etc) * a produces attribute listing the producer capabilities of the product (which topics the product is able to produce data for) * a consumes attribute, listing the consumer capabilities of the product * a triggers attribute, listing the trigger capabilities of the product * a executes attribute, listing the executor capabilities of the product Here is a example consumer capability: ... consumes: events: - mode: pull format: ECS - mode: push format: syslog ... This YAML strip tells that the product can consume the events topic in pull mode (aka active consumer, passive producer, as in HTTP GET) when events are formatted using ECS, and can consume events in push mode (aka passive consumer, active produver, as in syslog forwarding) as Syslog lines. Capabilities may be more generic ( e.g. no format constraint) or more specific ( e.g. add a protocol constraint to match). In all cases, two Products are said \"interoperable\" when we can find two corresponding capabilities of complementary role ( consumes -> produces or triggers -> executes ) of identical topic (\"events\" here) of matching constraints (mode, format, etc). When a constraint is unset, the capability is considered \"always matching\" ( e.g an ECS events producer will match a events consumer whose format is unset) Ideally, every product should define their full functional surface (incoming and outgoing data feeds, remlote API commands, etc) with appropriate constraint to clearly state their complete interop potential. This can be cumbersome, so Meshroom comes with a predefined set of Product Templates you can use to scaffold your own product. The templates catalog is sourced from Gartner's Hype Cycle for Security Operations, 2024 and tries to cover all cybersecurity scopes, but feel free to contribute new templates if you feel we missed some product categories. To create a new product in your Meshroom project, simply use the meshroom create product command. You may base your product on an existing template via meshroom create product --from <template> You can list and search available products in the current project via meshroom list products Integration To be interoperable, most product capabilities can't just be declared, some must be programmatically configured, some even involve pushing custom code or calling multiple APIs to get up-and-running. The recipe of setting up a consumer/producer/trigger/executor capability on a product is termed an Integration . Some Integrations will simply be implicitly rendered by their product's YAML manifest. For example, an exposed HTTP GET API at a given URL is fully described by its HTTP nature, the method used, the endpoint's URL and accepted path and query params. As in an Open API manifest, this information is enough to interconnect with a 3rd-party. Integrations that require specific configuration procedures can be explicitly defined via python hooks (see Hooks ) in the product's integrations folders. Python files insides those folders are automatically interpreted and used when calling meshroom up to know how to configure each end of a Plug edge, yielding an up-and-running interop between both products. You can create an integration via meshroom create integration <product> <target_product> <topic> [options...] You can see that an integration is always about a specific topic. If a given product endpoint serves multiple purposes, you shall define as many Integrations as necessary to cover the actual functional scope of it. You can list and search among existing integrations using meshroom list integrations Instance Once your project defines a Capabilities Graph of Products and Integrations , you're ready to define a Mesh architecture by picking up among its allowed nodes and edges. In a mesh, nodes are called Instances and edges are called Plugs You can add a new instance of a given product using meshroom add <product> [instance_name] If the product declares required settings (like API keys, cloud region, URL, etc), you will be asked for their values, interactively. Fields declared as secrets in the product's YAML manifest will be securely stored in the project's GPG store. You can list defined instances using meshroom list instances And (re-)configure settings for an instance using meshroom configure <instance_name> Your project's Instances and GPG store form a handy bundle of your full SOC's product constellation, versioning and securely storing all the necessary material to administrate and interoperate this ecosystem in a well-defined hierarchy. Plug Instances communicate with eachother via so-called Plugs . Plugs are the edge of your mesh's graph. A Plug makes use of: * a source Integration on the source product at the edge's origin * a destination Integration on the destination product at the opposite end. A Plug always carries a single topic, in a single mode. When setting up a Plug using 2 integrations, the plug inherits its format and other constraints from the most specific combination of both integrations' constraints. When no matching constraint set can be found out of all existing Integrations, the Plug can't be created and the two product instances won't be able to communicate. You can then build new integration, perhaps more generic, to cover your desired Plug's need, on one or both ends of the edge (see Integrations ). You can plug two Instances using meshroom plug <source_instance> <destination_instance> <topic> [options...] and unplug an existing plug using meshroom unplug <source_instance> <destination_instance> <topic> [options...] Note that there can only be one plug at a time for each set of constraints. You can get several plugs on the same Instances pair for the same topic by narrowing their constraint sets. You can list and search plugs using meshroom list plugs Up/down Once your mesh is defined, you can apply it to your real product tenants via a single command: meshroom up The opposite operation being meshroom down Like in docker compose (for those familiar with it), up/down is the core value of Meshroom : it allows to configure a full mesh in a single call, that will be resolved by Meshroom CLI to a sequence of configuration operations submitted to your Instances based on the defined settings, secrets and Plugs. Ideally, you won't ever need to switch to your products' admin consoles. You may then assess the quality of your mesh interop via meshroom produce and meshroom watch commands, that respectively helps you producing and inspecting data flowing through your plugs. Hooks Many products require complex programmatic steps to setup an actual interop with a 3rd-party. The classical approach is to follow manual recipes from the products documentation, navigate through multiple admin panels and configuration forms to open the desired channel between two products. One of the main goals of Meshroom is to rationalize and fully automate these steps, so that meshroom up can submit the appropriate sequence of operations to all instances to configure the full mesh without direct user intervention. Willingness to favor remote tenant configuration via open APIs vary across vendors and solutions. Some products are simply not remote-configurable at all (think of adding syslog forwarding to an unexposed NGINX reverse-proxy). Others may require a very short but mandatory user navigation to their admin panel. Hopefully, more and more vendors embrace the CSMA philosophy and allow for completely remote configuration by 3rd-party providers. Meshroom takes into account those various regimes by allowing Products to define python hooks. Hooks are python decorated functions that will get executed in sequence upon meshroom up , taking the whole integration's context as arguments. Vendors and integrators can provide such hooks to implement automated procedures to remote-configure their product's capabilities. You can even provide boilerplate hooks to help user scaffold new integrations based on the products native extensibility features (plugins, custom formats, code addtions, etc ), and publish hooks to guide the user through the vendor's homologation process required to publish their contribution into the product's official integrations catalog (marketplace, github PRs, etc ). All hooks works by decorating vanilla python functions residing either inside the product's directory (for product-wide generic hooks) a specific integration's subdirectory (for plug-specific hooks that depend on a specific products couple) via one of the decorators defined in the meshroom.decorators package: hook decorator,called upon,usage,required @setup, meshroom up ,define an automated setup step to get a plug up-and-running on a given instance,optional @teardown, meshroom down ,define an automated step to shutdown and cleanup a plug from a given instance,optional @scaffold, meshroom create integration ,generate files for a new integration for a certain topic,optional @pull, meshroom pull ,generate integrations by pulling the vendor's online integration catalog,required @publish, meshroom publish ,submit all defined integrations to the vendor's catalog for public homologation,required @produce, meshroom produce ,send data to the plug's destination for testing,required @watch, meshroom watch ,inspect data flowing through the plug,required Hooks may specify an order (an integer or 'first'/'last' keywords) field to order the setup sequence. Hooks marked as \"required\" are required for the corresponding Meshroom command to work on the said product. They are not mandatory for a product definition to be valid, but not all meshroom command will be available until these hooks are implemented. Meshroom project structure A Meshroom project is a git-backed directory on your computer, that you can version and share via your favorite online git service. The local project itself has the following structure: \u2503 \u2523\u2501 products \ud83e\udfa4\u2501\u2501\u2501 All products available in the capabilities graph \u2503 \u2517\u2501 product_a \u2503 \u2523\u2501 definition.yaml \ud83e\udfa4\u2501\u2501\u2501 Define capabilities of product_a \u2503 \u2523\u2501 setup.py \ud83e\udfa4\u2501\u2501\u2501 Various python files with generic hooks for product_a's integrations \u2503 \u2517\u2501 integrations \ud83e\udfa4\u2501\u2501\u2501 All integration offered by product_a \u2503 \u2517\u2501 product_b \ud83e\udfa4\u2501\u2501\u2501 All integration offered by product_a with product_b \u2503 \u2523\u2501 events_consumer.yaml \ud83e\udfa4\u2501\u2501\u2501 An integration product_a -[events]-> product_b in push mode \u2503 \u2523\u2501 events_consumer.py \ud83e\udfa4\u2501\u2501\u2501 Hooks for the above integration \u2503 \u2523\u2501 events_consumer_pull.yaml \ud83e\udfa4\u2501\u2501\u2501 An integration product_a -[events]-> product_b in pull mode \u2503 \u2517\u2501 events_consumer_pull.py \ud83e\udfa4\u2501\u2501\u2501 Hooks for this latter integration \u2503 \u2517\u2501 product_b \u2503 \u2517\u2501 ... \ud83e\udfa4\u2501\u2501\u2501 same structure for each product... \u2503 \u2523\u2501 instances \ud83e\udfa4\u2501\u2501\u2501 Define the instances used in this project's mesh \u2503 \u2517\u2501 product_a \ud83e\udfa4\u2501\u2501\u2501 Instances for product_a \u2503 \u2517\u2501 instance_a \ud83e\udfa4\u2501\u2501\u2501 Some product_a's instance, here called \"instance_a\" \u2503 \u2523\u2501 config.yaml \ud83e\udfa4\u2501\u2501\u2501 Non-sensitive configuration for instance_a \u2503 \u2517\u2501 plugs \ud83e\udfa4\u2501\u2501\u2501 Plugs whose source is instance_a \u2503 \u2517\u2501 instance_b \ud83e\udfa4\u2501\u2501\u2501 Plugs whose destination is instance_b \u2503 \u2517\u2501 event_consumer_pull.yaml \ud83e\udfa4\u2501\u2501\u2501 Config for plug instance_a -[events]-> instance_b in pull mode \u2503 \u2517\u2501 product_b \u2503 \u2517\u2501 instance_product_b \u2503 \u2517\u2501 ... \u2523\u2501 secrets.gpg \ud83e\udfa4\u2501\u2501\u2501 GPG-encrypted store of all instances' secrets This is a minimal example, your project may contain additional files, such as .gitignore, README.md and other documentation or scripts for automating stuff.","title":"Concepts"},{"location":"concepts/#concepts","text":"","title":"Concepts"},{"location":"concepts/#integration-lifecycle","text":"TODO CYCLE SCHEMA","title":"Integration lifecycle"},{"location":"concepts/#capabilities-graph","text":"Formally, a cybersecurity mesh architecture (CSMA) is a directed graph of products talking to eachother. More precisely, it is an overlay of 2 graphs: The capabilities graph , which expresses the set of all products that can be interoperated with eachother and what functional capacity they expose. Nodes of this graph are Product capabilities, and edges connect complementary capabilities. For example, one product may consume alerts produced by another product, or can execute actions triggered by another one. Edges thus characterise interop opportunities about a certain Topic between a source product and a destination product. The direction of the edges materializes the dataflow : the source product produces/triggers information (resp. actions) that the destination product consumes/executes . An edge exists as soon as the products define a compatible producer (or trigger) / consumer (resp. executor) pair of Integrations . The edge also carries the roles in the data exchange in push mode, the producer is active and the consumer is passive ( e.g. a Syslog forwarder) in pull mode, the producer is passive and the consumer is active ( e.g. an HTTP GET API) Therefore, an edge exist between product couples that expose complementary integrations for compatible topics, and match formats or other compatibility criteria you may need to refine the scope of a capability. The density if the capabilities graph measures the \"openness\" of the products constellation ; one wants to maximize the number of allowed interops between cybersecurity solutions available on the market The Mesh graph itself, which is an instanciation of several product Instances connected to eachother by Plugs who leverage compatible Integrations over the underlying capabilities graph. Instances correspond to actual user tenants of the underlying products, and plugs are live connections between those tenants. In order to setup the defined plugs, instances must be configured to enable the corresponding production/consumption triggering/execution logic, potentially via custom additions to the products themselves. Meshroom's spirit is to make all this configuration and provisioning as simple as a single meshroom up command. To do so, Products, Integrations, Instances and Plugs are defined via YAML manifests and vendor code additions when required. All these files belong to a git-backed repository that can be shared, versioned via git and manipulated via the Meshroom CLI, exactly as, say, Helm charts can be shared among a community of Kubernetes users. Some sensitive data , like API keys and other secrets used to teleoperate the Instances are natively held and managed by Meshroom in a local GPG secrets store , that can also be shared following a classical GPG assymetric cryptography process. This decreases the risk of leak resulting from a spread of secrets used to co-ordinate numerous tenants, while easing the sharing of a full read-to-use SOC configuration.","title":"Capabilities graph"},{"location":"concepts/#project","text":"A Meshroom Project is a git-backed local directory on your computer, following a file structure the Meshroom CLI can understand and manipulate (see Meshroom project structure ). You can start a new meshroom project via meshroom init <path> . This will setup a new local git repo and few minimal files in this directory so that you can start building your integrations and mesh architecture. You can then directly add a git remote via git remote add <remote> <remote_url> such as a GitHub repo to save, share and publish your project via git push , and use the directory as a classical Git repository. Subsequent meshroom commands must be executed at the <path> 's root and will manipulate its files hierarchy.","title":"Project"},{"location":"concepts/#product","text":"In Meshroom, a Product is the definition of a cybersecurity product's capabilities. A Product is primarily defined via a YAML file with: * a name * a textual description of its functional surface and its role in the security ecosystem * a set of tags , expliciting the product category it belongs to ( e.g. , EDR, EASM, SIEM, etc) * a produces attribute listing the producer capabilities of the product (which topics the product is able to produce data for) * a consumes attribute, listing the consumer capabilities of the product * a triggers attribute, listing the trigger capabilities of the product * a executes attribute, listing the executor capabilities of the product Here is a example consumer capability: ... consumes: events: - mode: pull format: ECS - mode: push format: syslog ... This YAML strip tells that the product can consume the events topic in pull mode (aka active consumer, passive producer, as in HTTP GET) when events are formatted using ECS, and can consume events in push mode (aka passive consumer, active produver, as in syslog forwarding) as Syslog lines. Capabilities may be more generic ( e.g. no format constraint) or more specific ( e.g. add a protocol constraint to match). In all cases, two Products are said \"interoperable\" when we can find two corresponding capabilities of complementary role ( consumes -> produces or triggers -> executes ) of identical topic (\"events\" here) of matching constraints (mode, format, etc). When a constraint is unset, the capability is considered \"always matching\" ( e.g an ECS events producer will match a events consumer whose format is unset) Ideally, every product should define their full functional surface (incoming and outgoing data feeds, remlote API commands, etc) with appropriate constraint to clearly state their complete interop potential. This can be cumbersome, so Meshroom comes with a predefined set of Product Templates you can use to scaffold your own product. The templates catalog is sourced from Gartner's Hype Cycle for Security Operations, 2024 and tries to cover all cybersecurity scopes, but feel free to contribute new templates if you feel we missed some product categories. To create a new product in your Meshroom project, simply use the meshroom create product command. You may base your product on an existing template via meshroom create product --from <template> You can list and search available products in the current project via meshroom list products","title":"Product"},{"location":"concepts/#integration","text":"To be interoperable, most product capabilities can't just be declared, some must be programmatically configured, some even involve pushing custom code or calling multiple APIs to get up-and-running. The recipe of setting up a consumer/producer/trigger/executor capability on a product is termed an Integration . Some Integrations will simply be implicitly rendered by their product's YAML manifest. For example, an exposed HTTP GET API at a given URL is fully described by its HTTP nature, the method used, the endpoint's URL and accepted path and query params. As in an Open API manifest, this information is enough to interconnect with a 3rd-party. Integrations that require specific configuration procedures can be explicitly defined via python hooks (see Hooks ) in the product's integrations folders. Python files insides those folders are automatically interpreted and used when calling meshroom up to know how to configure each end of a Plug edge, yielding an up-and-running interop between both products. You can create an integration via meshroom create integration <product> <target_product> <topic> [options...] You can see that an integration is always about a specific topic. If a given product endpoint serves multiple purposes, you shall define as many Integrations as necessary to cover the actual functional scope of it. You can list and search among existing integrations using meshroom list integrations","title":"Integration"},{"location":"concepts/#instance","text":"Once your project defines a Capabilities Graph of Products and Integrations , you're ready to define a Mesh architecture by picking up among its allowed nodes and edges. In a mesh, nodes are called Instances and edges are called Plugs You can add a new instance of a given product using meshroom add <product> [instance_name] If the product declares required settings (like API keys, cloud region, URL, etc), you will be asked for their values, interactively. Fields declared as secrets in the product's YAML manifest will be securely stored in the project's GPG store. You can list defined instances using meshroom list instances And (re-)configure settings for an instance using meshroom configure <instance_name> Your project's Instances and GPG store form a handy bundle of your full SOC's product constellation, versioning and securely storing all the necessary material to administrate and interoperate this ecosystem in a well-defined hierarchy.","title":"Instance"},{"location":"concepts/#plug","text":"Instances communicate with eachother via so-called Plugs . Plugs are the edge of your mesh's graph. A Plug makes use of: * a source Integration on the source product at the edge's origin * a destination Integration on the destination product at the opposite end. A Plug always carries a single topic, in a single mode. When setting up a Plug using 2 integrations, the plug inherits its format and other constraints from the most specific combination of both integrations' constraints. When no matching constraint set can be found out of all existing Integrations, the Plug can't be created and the two product instances won't be able to communicate. You can then build new integration, perhaps more generic, to cover your desired Plug's need, on one or both ends of the edge (see Integrations ). You can plug two Instances using meshroom plug <source_instance> <destination_instance> <topic> [options...] and unplug an existing plug using meshroom unplug <source_instance> <destination_instance> <topic> [options...] Note that there can only be one plug at a time for each set of constraints. You can get several plugs on the same Instances pair for the same topic by narrowing their constraint sets. You can list and search plugs using meshroom list plugs","title":"Plug"},{"location":"concepts/#updown","text":"Once your mesh is defined, you can apply it to your real product tenants via a single command: meshroom up The opposite operation being meshroom down Like in docker compose (for those familiar with it), up/down is the core value of Meshroom : it allows to configure a full mesh in a single call, that will be resolved by Meshroom CLI to a sequence of configuration operations submitted to your Instances based on the defined settings, secrets and Plugs. Ideally, you won't ever need to switch to your products' admin consoles. You may then assess the quality of your mesh interop via meshroom produce and meshroom watch commands, that respectively helps you producing and inspecting data flowing through your plugs.","title":"Up/down"},{"location":"concepts/#hooks","text":"Many products require complex programmatic steps to setup an actual interop with a 3rd-party. The classical approach is to follow manual recipes from the products documentation, navigate through multiple admin panels and configuration forms to open the desired channel between two products. One of the main goals of Meshroom is to rationalize and fully automate these steps, so that meshroom up can submit the appropriate sequence of operations to all instances to configure the full mesh without direct user intervention. Willingness to favor remote tenant configuration via open APIs vary across vendors and solutions. Some products are simply not remote-configurable at all (think of adding syslog forwarding to an unexposed NGINX reverse-proxy). Others may require a very short but mandatory user navigation to their admin panel. Hopefully, more and more vendors embrace the CSMA philosophy and allow for completely remote configuration by 3rd-party providers. Meshroom takes into account those various regimes by allowing Products to define python hooks. Hooks are python decorated functions that will get executed in sequence upon meshroom up , taking the whole integration's context as arguments. Vendors and integrators can provide such hooks to implement automated procedures to remote-configure their product's capabilities. You can even provide boilerplate hooks to help user scaffold new integrations based on the products native extensibility features (plugins, custom formats, code addtions, etc ), and publish hooks to guide the user through the vendor's homologation process required to publish their contribution into the product's official integrations catalog (marketplace, github PRs, etc ). All hooks works by decorating vanilla python functions residing either inside the product's directory (for product-wide generic hooks) a specific integration's subdirectory (for plug-specific hooks that depend on a specific products couple) via one of the decorators defined in the meshroom.decorators package: hook decorator,called upon,usage,required @setup, meshroom up ,define an automated setup step to get a plug up-and-running on a given instance,optional @teardown, meshroom down ,define an automated step to shutdown and cleanup a plug from a given instance,optional @scaffold, meshroom create integration ,generate files for a new integration for a certain topic,optional @pull, meshroom pull ,generate integrations by pulling the vendor's online integration catalog,required @publish, meshroom publish ,submit all defined integrations to the vendor's catalog for public homologation,required @produce, meshroom produce ,send data to the plug's destination for testing,required @watch, meshroom watch ,inspect data flowing through the plug,required Hooks may specify an order (an integer or 'first'/'last' keywords) field to order the setup sequence. Hooks marked as \"required\" are required for the corresponding Meshroom command to work on the said product. They are not mandatory for a product definition to be valid, but not all meshroom command will be available until these hooks are implemented.","title":"Hooks"},{"location":"concepts/#meshroom-project-structure","text":"A Meshroom project is a git-backed directory on your computer, that you can version and share via your favorite online git service. The local project itself has the following structure: \u2503 \u2523\u2501 products \ud83e\udfa4\u2501\u2501\u2501 All products available in the capabilities graph \u2503 \u2517\u2501 product_a \u2503 \u2523\u2501 definition.yaml \ud83e\udfa4\u2501\u2501\u2501 Define capabilities of product_a \u2503 \u2523\u2501 setup.py \ud83e\udfa4\u2501\u2501\u2501 Various python files with generic hooks for product_a's integrations \u2503 \u2517\u2501 integrations \ud83e\udfa4\u2501\u2501\u2501 All integration offered by product_a \u2503 \u2517\u2501 product_b \ud83e\udfa4\u2501\u2501\u2501 All integration offered by product_a with product_b \u2503 \u2523\u2501 events_consumer.yaml \ud83e\udfa4\u2501\u2501\u2501 An integration product_a -[events]-> product_b in push mode \u2503 \u2523\u2501 events_consumer.py \ud83e\udfa4\u2501\u2501\u2501 Hooks for the above integration \u2503 \u2523\u2501 events_consumer_pull.yaml \ud83e\udfa4\u2501\u2501\u2501 An integration product_a -[events]-> product_b in pull mode \u2503 \u2517\u2501 events_consumer_pull.py \ud83e\udfa4\u2501\u2501\u2501 Hooks for this latter integration \u2503 \u2517\u2501 product_b \u2503 \u2517\u2501 ... \ud83e\udfa4\u2501\u2501\u2501 same structure for each product... \u2503 \u2523\u2501 instances \ud83e\udfa4\u2501\u2501\u2501 Define the instances used in this project's mesh \u2503 \u2517\u2501 product_a \ud83e\udfa4\u2501\u2501\u2501 Instances for product_a \u2503 \u2517\u2501 instance_a \ud83e\udfa4\u2501\u2501\u2501 Some product_a's instance, here called \"instance_a\" \u2503 \u2523\u2501 config.yaml \ud83e\udfa4\u2501\u2501\u2501 Non-sensitive configuration for instance_a \u2503 \u2517\u2501 plugs \ud83e\udfa4\u2501\u2501\u2501 Plugs whose source is instance_a \u2503 \u2517\u2501 instance_b \ud83e\udfa4\u2501\u2501\u2501 Plugs whose destination is instance_b \u2503 \u2517\u2501 event_consumer_pull.yaml \ud83e\udfa4\u2501\u2501\u2501 Config for plug instance_a -[events]-> instance_b in pull mode \u2503 \u2517\u2501 product_b \u2503 \u2517\u2501 instance_product_b \u2503 \u2517\u2501 ... \u2523\u2501 secrets.gpg \ud83e\udfa4\u2501\u2501\u2501 GPG-encrypted store of all instances' secrets This is a minimal example, your project may contain additional files, such as .gitignore, README.md and other documentation or scripts for automating stuff.","title":"Meshroom project structure"},{"location":"commands/create_product/","text":"meshroom create product","title":"meshroom create product"},{"location":"commands/create_product/#meshroom-create-product","text":"","title":"meshroom create product"},{"location":"concepts/introduction/","text":"","title":"Introduction"}]}